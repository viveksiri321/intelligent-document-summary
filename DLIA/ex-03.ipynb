{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b309d451-e71b-4908-9c47-1c679c635330",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "# Define the data (input, expected output) \n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) \n",
        "y = np.array([0, 0, 0, 1]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4e23d4de-4160-4a33-a570-f3e6bd474ca3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define weights and biases (initialize randomly) \n",
        "weights1 = np.random.rand(2, 3)   # Weights for 1st hidden layer (2 \n",
        "                                                      #inputs, 3 hidden neurons) \n",
        "bias1 = np.random.rand(3)  # Bias for 1st hidden layer \n",
        "weights2 = np.random.rand(3, 1)  # Weights for 2nd hidden layer (3 \n",
        "                      #hidden neurons, 1 output) \n",
        "bias2 = np.random.rand()  # Bias for 2nd hidden layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "87fa98e6-3ec5-49bf-97d3-2a90c362ff52",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the learning rate \n",
        "learning_rate = 0.1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bc5f90b4-6191-4fcd-836c-edd019999e20",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function for calculating the sigmoid activation \n",
        "def sigmoid(x): \n",
        "   return 1 / (1 + np.exp(-x)) \n",
        "# Function for calculating the derivative of sigmoid (used later) \n",
        "def sigmoid_derivative(x): \n",
        "   return sigmoid(x) * (1 - sigmoid(x)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3da6d89e-7ae0-408a-8ab4-56129d02a78c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Iterate over all data points for multiple updates \n",
        "for i in range(len(X)): \n",
        "  x = X[i]  # Input values \n",
        "  target = y[i]  # Expected output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e33b5db9-8d67-45ec-9c43-6937d6a3206d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Forward Pass \n",
        "# 1st Hidden Layer \n",
        "z1 = np.dot(x, weights1) + bias1  # Weighted sum for 1st hidden layer \n",
        "a1 = sigmoid(z1)  # Activation for 1st hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3aa2d418-eedc-4eb7-925c-4610e43b8cf7",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 2nd Hidden Layer \n",
        "z2 = np.dot(a1, weights2) + bias2  # Weighted sum for 2nd hidden \n",
        "#layer \n",
        "a2 = sigmoid(z2)  # Activation for 2nd hidden layer (output layer in \n",
        "#this case) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "75d5912f-acd2-4792-b8d7-927be43fc5bf",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Output \n",
        "output = a2 \n",
        "# Calculate the error \n",
        "error = target - output \n",
        "# Backpropagation \n",
        "# Output layer derivative \n",
        "output_derivative = sigmoid_derivative(a2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b32cfffb-0477-4d88-b7d7-550a0e217b6a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Propagate error back to 2nd hidden layer \n",
        "hidden2_derivative = output_derivative * error \n",
        "# Update weights and bias for 2nd hidden layer \n",
        "weights2_derivative = np.dot(a1.reshape(-1, 1), \n",
        "hidden2_derivative.reshape(1, -1)) \n",
        "weights2 -= learning_rate * weights2_derivative \n",
        "bias2 -= learning_rate * hidden2_derivative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bbca97f2-4864-44a5-9ca5-36ec57a1c8e4",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "hidden1_derivative = np.dot(weights2, hidden2_derivative) * sigmoid_derivative(z1) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1932660a-81da-4bf8-abd0-3060bd204333",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Update weights and bias for 1st hidden layer \n",
        "weights1_derivative = np.dot(x.reshape(-1, 1), hidden1_derivative.reshape(1, -1))  # Reshape hidden1_derivative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "39a67cbd-3d90-4a6b-96d2-51bd22bcc389",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "weights1 -= learning_rate * weights1_derivative \n",
        "bias1 -= learning_rate * hidden1_derivative.reshape(bias1.shape)\n",
        "# Reshape the derivative to match bias1's shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2f02ab0d-3533-421a-ad4c-3f9a7e012b4c",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Weights (Hidden Layer 1): [[0.14272818 0.92754705 0.50701531]\n",
            " [0.67960056 0.01677567 0.10650963]]\n",
            "Initial Bias (Hidden Layer 1): [0.79804331 0.64995133 0.00124546]\n",
            "Initial Weights (Hidden Layer 2): [[0.49435558]\n",
            " [0.82917343]\n",
            " [0.07727249]]\n",
            "Initial Bias (Hidden Layer 2): [0.05517789]\n",
            "\n",
            "Updated Weights (Hidden Layer 1) after Backpropagation: [[0.14272818 0.92754705 0.50701531]\n",
            " [0.67960056 0.01677567 0.10650963]]\n",
            "Updated Bias (Hidden Layer 1) after Backpropagation: [0.79804331 0.64995133 0.00124546]\n",
            "Updated Weights (Hidden Layer 2) after Backpropagation: [[0.49435558]\n",
            " [0.82917343]\n",
            " [0.07727249]]\n",
            "Updated Bias (Hidden Layer 2) after Backpropagation: [0.05517789]\n"
          ]
        }
      ],
      "source": [
        "# Print the results after iterating through all data points \n",
        "print(\"Initial Weights (Hidden Layer 1):\", weights1) \n",
        "print(\"Initial Bias (Hidden Layer 1):\", bias1) \n",
        "print(\"Initial Weights (Hidden Layer 2):\", weights2) \n",
        "print(\"Initial Bias (Hidden Layer 2):\", bias2) \n",
        "print(\"\\nUpdated Weights (Hidden Layer 1) after Backpropagation:\", weights1) \n",
        "print(\"Updated Bias (Hidden Layer 1) after Backpropagation:\", bias1)\n",
        "print(\"Updated Weights (Hidden Layer 2) after Backpropagation:\", \n",
        "weights2) \n",
        "print(\"Updated Bias (Hidden Layer 2) after Backpropagation:\", bias2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49064a85-063d-4ddb-930c-a50d94fc1dcb",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
