{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2435089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.datasets import cifar10 \n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input \n",
    "from tensorflow.keras.layers import Dense, Flatten \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361d2aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d675ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data \n",
    "x_train = x_train.astype('float32') / 255 \n",
    "x_test = x_test.astype('float32') / 255 \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) \n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251c8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 model without top layers \n",
    "base_model = VGG16(weights='imagenet', include_top=False, \n",
    "input_shape=(32, 32, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3953f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model layers \n",
    "for layer in base_model.layers: \n",
    "    layer.trainable = False \n",
    "# Add custom top layers \n",
    "x = base_model.output \n",
    "x = Flatten()(x) \n",
    "x = Dense(256, activation='relu')(x) \n",
    "predictions = Dense(10, activation='softmax')(x) \n",
    "# Create the final model \n",
    "model = Model(inputs=base_model.input, outputs=predictions) \n",
    "# Compile the model \n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "loss='categorical_crossentropy', \n",
    "metrics=['accuracy']) \n",
    "# Early stopping \n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, \n",
    "restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f03755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom top layers \n",
    "x = base_model.output \n",
    "x = Flatten()(x) \n",
    "x = Dense(256, activation='relu')(x) \n",
    "predictions = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58672370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model \n",
    "model = Model(inputs=base_model.input, outputs=predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5ad1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model \n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "loss='categorical_crossentropy', \n",
    "metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25800fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping \n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, \n",
    "restore_best_weights=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e017fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 254ms/step - accuracy: 0.5298 - loss: 1.3472 - val_accuracy: 0.5707 - val_loss: 1.2332\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 246ms/step - accuracy: 0.5923 - loss: 1.1682 - val_accuracy: 0.5886 - val_loss: 1.1775\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 404ms/step - accuracy: 0.6120 - loss: 1.1030 - val_accuracy: 0.5965 - val_loss: 1.1514\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 236ms/step - accuracy: 0.6294 - loss: 1.0553 - val_accuracy: 0.6007 - val_loss: 1.1563\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 243ms/step - accuracy: 0.6439 - loss: 1.0130 - val_accuracy: 0.6049 - val_loss: 1.1145\n",
      "313/313 - 49s - 158ms/step - accuracy: 0.6049 - loss: 1.1145\n",
      "\n",
      "Test accuracy: 0.6049000024795532\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, \n",
    "validation_data=(x_test, y_test), callbacks=[early_stop]) \n",
    "# Evaluate the model on the test set \n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2) \n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
